import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import openai
import os
import yaml
from dotenv import load_dotenv
from datetime import datetime
import logging


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# **1. Config íŒŒì¼ ë¡œë“œ í•¨ìˆ˜**
def load_config():
    config_path = os.path.join(os.getcwd(), "config.yml")
    try:
        with open(config_path, "r") as file:
            config = yaml.safe_load(file)
            if "text_columns" not in config or "tag_options" not in config:
                raise ValueError("Configì— 'text_columns' ë˜ëŠ” 'tag_options' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return config
    except Exception as e:
        st.error(f"config.yml íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return {}

# ìœ ì‚¬ë„ ê³„ì‚°
def calculate_similarity(user1, user2, feature_weights, all_features):
    similarity = 0
    for feature, weight in feature_weights.items():
        if feature in ['Age', 'Height', 'Weight']:
            max_val = all_features[feature].max()
            min_val = all_features[feature].min()
            if max_val != min_val:
                norm_diff = abs(user1[feature] - user2[feature]) / (max_val - min_val)
                similarity += (1 - norm_diff) * weight
            else:
                similarity += weight
        elif 'tags' in feature.lower():  # íƒœê·¸ ìœ ì‚¬ë„ ê³„ì‚°
            # íƒœê·¸ ì •ê·œí™” (ì†Œë¬¸ì ë³€í™˜ ë° ê³µë°± ì œê±°)
            user1_tags = set([tag.strip().lower() for tag in user1[feature].split(',')])
            user2_tags = set([tag.strip().lower() for tag in user2[feature].split(',')])

            # êµì§‘í•© / í•©ì§‘í•©ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
            tag_similarity = len(user1_tags & user2_tags) / len(
                user1_tags | user2_tags) if user1_tags | user2_tags else 0
            similarity += tag_similarity * weight
        else:
            similarity += (user1[feature] == user2[feature]) * weight
    return similarity / sum(feature_weights.values())

# ê·¸ë£¹ ìƒì„± : í´ëŸ¬ìŠ¤í„°ë§ ê·¸ë£¹ ìƒì„± ë° ì¬ë°°ì •.
def create_mixed_groups(users_df, all_features, feature_weights, min_group_size=6, max_group_size=8, min_females=3):
    females_df = users_df[users_df['Gender'] == 'Female']
    males_df = users_df[users_df['Gender'] == 'Male']

    # ì—¬ì„± ìˆ˜ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •
    n_clusters = max(len(females_df) // 3, 1)

    # ì—¬ì„±ì— ëŒ€í•´ K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    female_features = all_features.loc[females_df.index]
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    females_df['Cluster'] = kmeans.fit_predict(female_features)

    # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì—¬ì„± ê·¸ë£¹ ìƒì„±
    female_groups = [females_df[females_df['Cluster'] == i] for i in range(n_clusters)]

    # 3ëª… ë¯¸ë§Œ ê·¸ë£¹ ì¬ì¡°ì •
    def redistribute_females(groups, min_count):
        assigned_users = set()  # ì´ë¯¸ ê·¸ë£¹ì— í• ë‹¹ëœ ì‚¬ìš©ìë¥¼ ì¶”ì 
        while any(len(group) < min_count for group in groups):
            for i, group in enumerate(groups):
                if len(group) < min_count:
                    for j, other_group in enumerate(groups):
                        if len(other_group) > min_count:
                            # ê°€ì¥ ìœ ì‚¬ë„ê°€ ë‚®ì€ ì—¬ì„± ì°¾ê¸°
                            group_center = all_features.loc[group.index].mean()
                            other_group_similarities = all_features.loc[other_group.index].apply(
                                lambda x: cosine_similarity([x], [group_center])[0][0], axis=1
                            )
                            least_similar = other_group.loc[other_group_similarities.idxmin()]

                            # ì¤‘ë³µ í™•ì¸: ì´ë¯¸ ë°°ì •ëœ ì‚¬ìš©ìëŠ” ìŠ¤í‚µ
                            if least_similar.name in assigned_users:
                                continue

                            # ì‚¬ìš©ì ì´ë™ ë° ì¶”ì 
                            groups[i] = pd.concat([groups[i], least_similar.to_frame().T], ignore_index=True)
                            groups[j] = groups[j].drop(least_similar.name)
                            assigned_users.add(least_similar.name)
                            break
                    break
        return groups

    female_groups = redistribute_females(female_groups, min_females)

    # ê° ì—¬ì„± ê·¸ë£¹ì— ë‚¨ì„± ì¶”ê°€
    final_groups = []
    remaining_males = males_df.copy()

    for female_group in female_groups:
        group = female_group.copy()

        # ê·¸ë£¹ì— ë‚¨ì„± ì¶”ê°€ (ìµœëŒ€ 8ëª…ê¹Œì§€)
        males_to_add = min(max_group_size - len(group), len(remaining_males))

        if males_to_add > 0:
            male_similarities = remaining_males.apply(
                lambda male: np.mean([
                    calculate_similarity(male, female, feature_weights, all_features)
                    for _, female in group.iterrows()
                ]),
                axis=1
            )
            top_males = remaining_males.loc[male_similarities.nlargest(males_to_add).index]

            # ì¤‘ë³µ ë°©ì§€: ì„ íƒëœ ë‚¨ì„±ë“¤ì„ remaining_malesì—ì„œ ì œê±°
            group = pd.concat([group, top_males], ignore_index=True)
            remaining_males = remaining_males.drop(top_males.index)

        final_groups.append(group)

    return final_groups, remaining_males


def calculate_group_similarity(group, all_features, feature_weights):
    similarities = []
    for i in range(len(group)):
        for j in range(i + 1, len(group)):
            user1 = group.iloc[i]
            user2 = group.iloc[j]
            similarities.append(calculate_similarity(user1, user2, feature_weights, all_features))

    return np.mean(similarities) if similarities else 0


# **2. ììœ  í…ìŠ¤íŠ¸ íƒœê·¸ ìƒì„± í•¨ìˆ˜**
def generate_tags_from_text(column, text, config):
    if config and column in config['tag_options']:
        prompt = f"""
        ë¬¸ì¥: {text}
        ë‹¤ìŒ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê´€ë ¨ëœ íƒœê·¸ë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•´ ì£¼ì„¸ìš”:
        {', '.join(config['tag_options'][column])}.
        """
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}]
            )
            tags = response['choices'][0]['message']['content'].strip()
            print(f"Generated tags for {column}: {tags}")  # ë¡œê·¸ ì¶”ê°€
            return tags
        except Exception as e:
            logging.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return "API Error"
    return "No Tags"


# **3. ë‹¤ì¤‘ ê°’ ì»¬ëŸ¼ ì²˜ë¦¬ í•¨ìˆ˜**
def process_multi_value_column(column, df):
    # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´í•´ ì˜ˆì™¸ ë°©ì§€
    valid_data = df[column].fillna("").astype(str)

    # ì‰¼í‘œ(,)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ìì—´ì„ ë¶„ë¦¬
    split_data = valid_data.str.split(',', expand=True)

    # ê° ê°’ì— ëŒ€í•´ ì›-í•« ì¸ì½”ë”© ìˆ˜í–‰
    dummies = pd.get_dummies(split_data, prefix=column)

    # ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ìµœëŒ€ê°’ìœ¼ë¡œ ë³‘í•© (í•˜ë‚˜ë¼ë„ ê°’ì´ ìˆìœ¼ë©´ 1ë¡œ í‘œì‹œ)
    return dummies.groupby(level=0, axis=1).max()


# **4. ê·¸ë£¹ ì¬ë°°ì • í•¨ìˆ˜ (ì—¬ì„± ê·¸ë£¹ ë³´ì¶©)**
def reallocate_female_groups(female_groups, insufficient_groups):
    logging.debug(f"ì¬ë°°ì • ì „: {insufficient_groups}")
    while insufficient_groups:
        for donor_group in female_groups:
            if len(donor_group) > 3:
                recipient_group = insufficient_groups.pop(0)
                additional_female = donor_group.iloc[-1:]
                recipient_group = pd.concat([recipient_group, additional_female], ignore_index=True)
                donor_group.drop(additional_female.index, inplace=True)
                if len(recipient_group) >= 3:
                    female_groups.append(recipient_group)
                break
    logging.debug(f"ì¬ë°°ì • í›„: {insufficient_groups}")

# **5. ë‚¨ì„± ê·¸ë£¹ ìƒì„± ë° ë°°ì • í•¨ìˆ˜**
def assign_male_to_groups(female_groups, males_df, all_features):
    groups = []
    male_features = all_features.iloc[males_df.index]

    for female_group in female_groups:
        female_group_features = all_features.loc[female_group.index]

        # ë‚¨ì„± ì¸ì›ê³¼ ì—¬ì„± ê·¸ë£¹ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        male_similarity = calculate_cosine_similarity(male_features, female_group_features)

        # í•„ìš”í•œ ë‚¨ì„± ì¸ì› ìˆ˜ ê³„ì‚° (ìµœëŒ€ 8ëª…ê¹Œì§€, ë‚¨ì•„ìˆëŠ” ë‚¨ì„± ìˆ˜ë³´ë‹¤ ì´ˆê³¼í•˜ì§€ ì•ŠìŒ)
        num_males_needed = min(8 - len(female_group), len(males_df))

        if num_males_needed > 0 and not males_df.empty:
            # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ ì„ íƒ (ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤ ì œê±°)
            top_male_idxs = np.argsort(male_similarity.flatten())[::-1][:num_males_needed]
            valid_idxs = [idx for idx in top_male_idxs if idx < len(males_df)]

            if valid_idxs:
                # ìœ íš¨í•œ ì¸ë±ìŠ¤ë¥¼ í†µí•´ ë‚¨ì„± ê·¸ë£¹ ìƒì„±
                male_group = males_df.iloc[valid_idxs]
                males_df = males_df.drop(male_group.index).reset_index(drop=True)
            else:
                male_group = pd.DataFrame()  # ìœ íš¨í•œ ì¸ë±ìŠ¤ê°€ ì—†ì„ ë•Œ ë¹ˆ ê·¸ë£¹
        else:
            male_group = pd.DataFrame()  # í•„ìš”í•œ ì¸ì›ì´ ì—†ì„ ë•Œ ë¹ˆ ê·¸ë£¹

        # ìµœì¢… ê·¸ë£¹ ìƒì„±
        final_group = pd.concat([female_group, male_group], ignore_index=True)
        groups.append(final_group)

    return groups, males_df


# **6. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜**
def calculate_cosine_similarity(male_features, female_group_features):
    return cosine_similarity(
        male_features, female_group_features.mean(axis=0).values.reshape(1, -1)
    )

# **7. ë‚¨ì€ ì¸ì› ì¬ë°°ì • í•¨ìˆ˜**
def allocate_remaining_users(groups, remaining_males):
    for group in groups:
        while len(group) < 6 and not remaining_males.empty:
            user = remaining_males.iloc[0:1]
            group = pd.concat([group, user], ignore_index=True)
            remaining_males = remaining_males.drop(user.index).reset_index(drop=True)

        if len(group) < 6 and remaining_males.empty:
            st.warning(f"ê·¸ë£¹ {groups.index(group) + 1}ì— ìµœì†Œ ì¸ì›ì„ ì±„ìš°ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# **8. AI ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜**
def generate_openai_response(summary, tags):
    prompt = f"""
    ë‹¤ìŒì€ í•œ ê·¸ë£¹ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤:

    {summary}

    ê·¸ë£¹ ë‚´ íƒœê·¸ í†µê³„: {tags}

    ì´ ê·¸ë£¹ì˜ íŠ¹ì§•ê³¼ íƒœê·¸ í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ê·¸ë£¹ ë‚´ì˜ ì‚¬ëŒë“¤ì´ ì„œë¡œì—ê²Œ í˜¸ê°ì„ ê°€ì§ˆë§Œí•œ ì´ìœ ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. 
    ë¶„ì„ì€ ê°€ê¸‰ì  íƒœê·¸ í†µê³„ì— ë¹„ì¤‘ì„ ë†’ê²Œ ë‘ê³  ë¶„ì„í•´ì£¼ì„¸ìš”. ê·¸ë¦¬ê³  ì„œë¡œì—ê²Œ ê¶ê¸ˆí•´í•  ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. 
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        st.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return ""

# **9. ë©”ì¸ ì‹¤í–‰ ë¡œì§**
def main():
    config = load_config()
    feature_weights = config.get("feature_weights", {})
    if not feature_weights:
        st.warning("feature_weights ì„¤ì •ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="xlsx")

    if uploaded_file:
        df = pd.read_excel(uploaded_file)
        st.write("ì—…ë¡œë“œëœ ìœ ì € ë°ì´í„°:", df)

        # ë°ì´í„° í†µê³„ ì¶œë ¥
        st.markdown("### ì—…ë¡œë“œëœ ì „ì²´ ë°ì´í„° í†µê³„ ìš”ì•½")
        total_applicants = len(df)
        male_count = len(df[df['Gender'] == 'Male'])
        female_count = len(df[df['Gender'] == 'Female'])
        male_ratio = (male_count / total_applicants) * 100 if total_applicants > 0 else 0
        female_ratio = (female_count / total_applicants) * 100 if total_applicants > 0 else 0
        average_age = df['Age'].mean()
        average_height = df['Height'].mean()
        average_weight = df['Weight'].mean()

        st.write(f"ğŸ”¢ **ì´ ì‹ ì²­ì ìˆ˜**: {total_applicants}ëª…")
        st.write(f"ğŸ‘¨â€ğŸ’¼ **ë‚¨ì„± ì¸ì›**: {male_count}ëª… ({male_ratio:.2f}%)")
        st.write(f"ğŸ‘©â€ğŸ’¼ **ì—¬ì„± ì¸ì›**: {female_count}ëª… ({female_ratio:.2f}%)")
        st.write(f"ğŸ“Š **í‰ê·  ë‚˜ì´**: {average_age:.1f}ì„¸")
        st.write(f"ğŸ“ **í‰ê·  í‚¤**: {average_height:.1f}cm")
        st.write(f"âš– **í‰ê·  ëª¸ë¬´ê²Œ**: {average_weight:.1f}kg")

        # ì¶”ê°€ í†µê³„ ì œì•ˆ: ì§€ì—­ ë¶„í¬, ì§ì—… ë¶„í¬, MBTI ë¶„í¬ ë“±
        st.write("**ì§€ì—­ë³„ ì‹ ì²­ì ìˆ˜**")
        st.write(df['Location'].value_counts())

        st.write("**ì§ì—…ë³„ ë¶„í¬**")
        st.write(df['Job'].value_counts())

        st.write("**MBTIë³„ ë¶„í¬**")
        st.write(df['MBTI'].value_counts())

        # 'My answer_tags_'ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì»¬ëŸ¼ ë³‘í•©í•˜ì—¬ 'Tags' ì»¬ëŸ¼ ìƒì„±
        tag_columns = df.filter(like='My answer_tags_').columns
        df['Tags'] = df[tag_columns].apply(lambda row: ','.join(row.dropna().astype(str)), axis=1)

        for column in config.get("text_columns", []):
            if column in df.columns:
                df[column + "_tags"] = df[column].apply(lambda x: generate_tags_from_text(column, str(x), config))
                df['Tags'] = df['Tags'] + ',' + df[column + "_tags"]
                tag_dummies = process_multi_value_column(column + "_tags", df)
                df = pd.concat([df, tag_dummies], axis=1)

        # ì¤‘ë³µ íƒœê·¸ ì œê±° ë° ì •ë¦¬
        df['Tags'] = df['Tags'].apply(lambda x: ','.join(set(tag.strip() for tag in x.split(',') if tag.strip())))
        st.write("ì²˜ë¦¬ í›„ Tags ì»¬ëŸ¼ ì˜ˆì‹œ:", df[['User ID', 'Tags']].head(10))
        print("ì²˜ë¦¬ í›„ Tags ì»¬ëŸ¼ ì˜ˆì‹œ: ", df[['User ID', 'Tags']].head())

        hobby_dummies = process_multi_value_column('Hobby', df)
        features = pd.get_dummies(df[['Preference', 'MBTI', 'Job', 'Gender']])
        numerical_features = df[['Age', 'Height', 'Weight']]
        all_features = pd.concat([features, hobby_dummies, numerical_features], axis=1)

        # ê·¸ë£¹ ìƒì„±
        all_groups, remaining_users = create_mixed_groups(df, all_features, feature_weights=feature_weights)

        # ê²°ê³¼ ì¶œë ¥ ë³´ê³ ì„œ
        current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        st.markdown(f"## {current_date} ì…”í”Œë§ ê³„íšì„œ")

        # ì…”í”Œë§ ê·¸ë£¹ ê²°ê³¼ ì¶œë ¥ >>>>
        for idx, group in enumerate(all_groups):
            # ê·¸ë£¹ ìœ ì‚¬ë„ ê³„ì‚°
            group_similarity = calculate_group_similarity(group, all_features, feature_weights)

            st.markdown(f"## ğŸŒŸ ì…”í”Œë§ ê·¸ë£¹ {idx + 1}")
            st.markdown(f"#### ğŸ“Œ ê¸°ë³¸ ì •ë³´")
            st.markdown(f" - ê·¸ë£¹ì¸ì›ìˆ˜: {len(group)}ëª… ({group['Gender'].value_counts().to_dict()})")
            st.markdown(f" - ê·¸ë£¹ë‚´ ìœ ì‚¬ë„ í‰ê· : {group_similarity:.2f}")
            st.markdown(f" - í‰ê· ë‚˜ì´: {group['Age'].mean():.1f}")
            summary = f"ì§ì—…: {', '.join(group['Job'].unique())}, " \
                      f"MBTI: {', '.join(group['MBTI'].unique())}, " \
                      f"í‰ê·  ë‚˜ì´: {group['Age'].mean():.1f}, ì„±ë¹„: {group['Gender'].value_counts().to_dict()}"

            # ê·¸ë£¹ì˜ ìœ íš¨í•œ Tags ì»¬ëŸ¼ì„ í™•ì¸í•˜ì—¬ ê²°í•©
            if 'Tags' in group.columns and not group['Tags'].isna().all():
                group_tags = ', '.join(group['Tags'].dropna().unique())
            else:
                group_tags = "No tags available"
            print(f"ê·¸ë£¹ {idx + 1}ì˜ íƒœê·¸: {group_tags}")

            st.write(group)  # ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ í‘œ

            # ê·¸ë£¹ íƒœê·¸ í†µê³„ ê³„ì‚°
            tag_stats = pd.Series(','.join(group['Tags'].dropna()).split(',')).value_counts()
            st.markdown("**ê·¸ë£¹ íƒœê·¸ í†µê³„**")
            st.write(tag_stats)

            # AI ì§ˆë¬¸ ìƒì„±
            ai_questions = generate_openai_response(summary, tag_stats)
            st.write("AI ìƒì„± ì§ˆë¬¸:", ai_questions)
            st.markdown("---")

        # ì „ì²´ ê·¸ë£¹ êµ¬ì„± ìš”ì•½
        st.markdown("\n ## ğŸ“Š ì „ì²´ ê·¸ë£¹ êµ¬ì„± ìš”ì•½:")
        st.write(f" ğŸ”¢ ì´ ê·¸ë£¹ ìˆ˜: {len(all_groups)}")
        st.write(f" ğŸ“ í‰ê·  ê·¸ë£¹ í¬ê¸°: {sum(len(group) for group in all_groups) / len(all_groups):.2f}")
        st.write(f" â¬‡ï¸ï¸ ìµœì†Œ ê·¸ë£¹ í¬ê¸°: {min(len(group) for group in all_groups)}")
        st.write(f" â¬† ìµœëŒ€ ê·¸ë£¹ í¬ê¸°: {max(len(group) for group in all_groups)}")
        st.markdown("---")

        # ë‚¨ì€ ì‚¬ìš©ì ì²˜ë¦¬
        if not remaining_users.empty:
            st.markdown("\n ## ğŸš¶â€â™‚ï¸ê·¸ë£¹ì— ë°°ì •ë˜ì§€ ì•Šì€ ì‚¬ìš©ì:")
            st.write(remaining_users)


if __name__ == "__main__":
    main()
